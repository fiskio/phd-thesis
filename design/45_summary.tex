\section{Summary}This chapter presented the design of the DISSP prototype system, a stream processing engine designed torealise the quality-centric data model described in Chapter~\ref{ch:data_model}.First, it presented the goals that drove the design of the system, such as the ability to performefficient processing under overload, the embedded calculation of the \sic metric and the support foradapting the \mbox{load-shedding} policy according to user needs.It explained how the theoretical concepts presented in the description of the data modelcan be implemented in the basic components of a stream processing system.The chapter then described the \emph{system-level components}, in particular their rolesand their interactions. In every DISSP deployment, queries run on one or more \emph{processingnodes}. These process tuples provided by a set of \emph{input providers} thatconvert external inputs to an appropriate system format. New queries are introduced into the system by a\emph{submitter}. For each query a \emph{coordinator} is spawned that is in charge of its deploymentand management. An \emph{oracle} oversees the processing of all queries, gathering information abouttheir performance and providing a global view of the system.After looking at the system as a whole, the focus shifted to the internal components of processingnodes. Every node exchanges command messages and tuples with other nodes and the oracle through a\emph{network layer}. An \emph{operator runner} routes tuples to the assigned subqueriesand manages their processing through the graph of operators. A \emph{load-shedder}overcomes overload by selecting tuples to be discarded, while a \emph{statistic manager} keepstrack of important metrics about the performance of a node.The chapter ended with the description of the deployment of a query. It used this workflow todescribe the detailed steps involved from the submission of a query to when itstarts processing.It explained how tuples and operators are compiled at run-time from an XML query description, and howthe original query graph is partitioned into subqueries to be deployed on multiple processing nodes.The next chapter focuses on the load-shedding process in more detail, presenting a \emph{fairshedding} algorithm that exploits the \sic metric to allocate resources among queries evenly. The goal is for them to all achieve the same performance in terms of the quality of the computed results.