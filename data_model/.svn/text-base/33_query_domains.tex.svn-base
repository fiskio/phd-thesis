\section{Query Domains}
In this section I will illustrate how to derive a metric describing the quantity of information captured
by tuples flowing through a query processing system based on the assumptions stated in
Section~\ref{sec:assumptions}.
In order to do so I will explore the two main families of queries, fan-in and fan-out,



\subsection{Fan-in queries}
\label{sec:fan-in}
The first class of queries we are going to analyse takes the name of \emph{fan-in}. In these queries the
input from \textit{many sources} is elaborated to produce a \textit{single result}. Typically in this category we find queries dealing
with a single aggregation, usually dealing with sensor data. These queries present a graph that resembles
a tree, with many input sources, a series of processing steps and a single point of output. 

\underline{\textsc{Example}}: Consider the query depicted in Figure~\ref{fig:query_fanin}. Three sources
produce input tuples at different rate over a certain period of time. All tuples for each source are
first collected by a time window and then averaged. Finally the maximum value among the one produced by
the average operator is selected and output. This is a typical fan-in query where input from many sources
is collected and processed to produce a single output.

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.6\textwidth]{img/tesi/query_fanin} 
	\caption{An example of fan-in query, input values for each source are first averaged over a certain
	time window, then the maximum is selected. Source Coverage Ratio values are shown for each tuple.}
	\label{fig:query_fanin}
\end{figure}

This figure also shows the individual \sic values of the tuples flowing through the query, let us
consider how this values are calculated. 

The final \sic value obtained is $3$, which is equal to the number of sources. This follows from
assumption $8$. This value is absolute, not scaled to the $[0,1]$ interval for comparison, to simplify
the exposition. It is also a perfect value, meaning that there was not loss of information during its
creation. In case of failure its value would be reduced by the amount of information contained in the
lost tuples.

According to Assumption $4$ all sources equally contribute to the creation of the final result.
Assumption $5$ then states that all tuples from a source in a \textit{source information tuple
set} contain the same amount of information. Figure~\ref{fig:query_fanin} show that each source assigns a
total value of 1 to the tuples it produces within a source information tuple set, and that the individual
\sic values are different according to the number of tuples produced. In this example the first source
produces only 2 tuples and thus the individual \sic value is $1/2$, while the third source produces 4
tuples with an individual value of $1/4$. 

The \textit{Average} operator takes in input a batch of tuples, of size 2, 3 and 4 respectively, and
outputs a single tuple. Because the amount of information going into an operator is equal to the amount
in output (Assumption 6), the newly generated tuples all contain a \sic value of 1. This is the sum of
the individual \sic values of the input tuples. 

The final \textit{Max} operator takes in input 3 tuples but only outputs 1. Nevertheless this final
tuple contains the total amount of information carried by the input tuples. The calculation remains
is unchanged because the model is operator independent as stated in Assumption~3. 

Let us consider what would happen to the final \sic value in case of the loss of a tuple, for instance a
source tuple produced by Source 3. In this case the amount of information of the tuple generated by the
average operator on the right would be $3/4$ instead of $1$. The loss of information, in the amount of
$1/4$ would then be propagated to the final tuple, which would have a \sic value of $9/4$ instead of $3$.
Because the calculation of the \sic values is additive, the amount of information missing, compared to
the maximum theoretical value, is equal to the sum of the \sic values of the individual tuples that were
lost during the processing.

\subsection{Fan-out queries} 
\label{sec:fan-out}

The second class of queries that we consider is called \textit{fan-out}. This is the family of queries
where one or more operators send their output to \textit{more than one} downstream operators.
Differently than \textit{fan-in} queries, where the graph resembles a tree, \textit{fan-out} present a
query graph which can assume many more configurations, with the only requirement to be acyclic.
Fan-out queries can be divided into 2 main classes: \emph{a)} queries with one result but split
computation, and \emph{b)} queries calculating more than one result. I am going to describe an example for each case,
showing how the \sic calculation is derived from the assumtion stated in the previous section.

\textbf{Split computation queries} are similar to the map-reduce processing paradigm. Because one or more
operators are too computationally heavy to be hosted on a single processing node, their computation is
split among a certain number of copies, running at different sites. These copies are all composed by the
same set of operators, but process only a suset of the original data. Splitting the computation allows
the system to spread the processing cost of a set of operators over several nodes and overcome the
overload condition at the original hosting node. 

Figure~\ref{fig:fanout_mr} shows a query processing Twitter data in real-time. A stream of Twitter
messages can be analysed to extract several different properties at once. Every message contains a lot
of information in addition to the message text itself, like the location where it was sent from and some
information about the author. Table~\ref{tab:tweet} shows the structure of a message and the associated
metadata. 

In this query 300 messages are processed during a time-window, each is analysed by a Natuaral Language
Processing (NLP) operator that calculates a coefficient based on the text of the message text, finally a
max operator outputs the message with the highest coefficient. We assume that the NLP operator is very
computationally intensive and would overload a single node at the current rate. Because of this the
computation is split onto 3 different nodes, each processing 1/3 of the messages, which can then process
all the messages without the need to discard a portion of them.
\include{data_model/tweet_table}
In this case the \textit{Split} operator only makes a partition of the original stream, without
data duplication, meaning that the tuples it outputs still have the same \sic value as the ones in input. 
 In this query the split operators receives in input 300 tuples each with a \sic
value of 1/300 and outputs 100 tuples on each output stream, again having an individual \sic value of 1/300. Each stream is sent to a different
processing node where a NLP operator assigns a coefficient to each message. These operators output the
same number of tuples they receive in input, thus producing 100 tuples each with an individual \sic value
of 1/300. Finally all the tuples are received by a Top-10 operator which outputs the 10 tuples having the
maximum coefficient. Each output tuple has a \sic value of 1/10, bearing a total final \sic value of 1.

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.6\textwidth]{img/tesi/fan-out_mr} 
	\caption{An example of fan-out query processing Twitter data implementing the map-reduce paradigm. It
	calculates a value to each tuple based on a natural language processing operator. Because of the heavy
	computational cost of these operators, the data is split onto 3 nodes and processed separately. Finally
	a max operator determines the message with the highest value.}
	\label{fig:fanout_mr}
\end{figure}

\textbf{Multiple results queries} produce several outputs from the same set of input data. These can be
seen as multiple single output queries, with a partial overlap in their computation. When analysing a
stream of data, a user might be interested in obtaining several different results. Instead of submitting
$N$ queries though, it can submit a single fan-out query with multiple ending points. This is
conceptually simpler than having to design and submit several almost identical queries and directly
expluits the processing redundancy by reusing a number of streams and operators.

Figure~\ref{fig:query_fanout} shows a query calculating the occurrence of positive and negative mentions
of a certain keyword and also calculates their ratio. The original stream comes from the Twitter firehose
and contains an usorted stream of messages. In our example, during a time-window, it delivers 3 messages
with individual \sic values of 1/3. Then a Filter operator select only those messages containing a
certain keyword, in our example it outputs 2 tuples. At this point the output of the Filter operator is 
\textit{multiplexed} over two different operators, one that filters only messages containing a positive
reference to the keyword and one filtering for negative references. 

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.6\textwidth]{img/tesi/fan-out_2} 
	\caption{An example of fan-out query processing Twitter data. It counts the occurrence of positive and
	negative mentions of a certain keyword, giving also their ratio. The numbers shown on tuples are the
	individual \sic values.}
	\label{fig:query_fanout}
\end{figure}

Assumption 9 from the previous section tells us that when such a multiplication of the output occurs, the
total \sic value has to be distributed over all the output tuples. This is also in accordance to
Assumption 6, which states the principle of information conservation. Each output stream of the Keyword
Filter operator then contains an identical set of 2 tuples, each having an individual \sic value of 1/4.
The positive and the negative filter then each outputs a single tuple, with a \sic value of 1/2. 

These go in input to a Counter operator on each side. These operators produce 2 output streams, one that
is terminal and is delivered as a result and another that feeds into a Ratio operator. Again the output
of the Counter operators is multiplexed and thus the individual \sic values of the produced tuples is
scaled accordingly. In our example each Counter produces 2 identical batches of 1 tuple having a \sic
value of 1/4. The Ratio operator outputs the third result of the query, producing a single tuple with
\sic value of 1/2.

This query computes 3 different results: the number of messages with a positive mention of a keyword,
the number of with a negative one and their ratio. The result tuples have different \sic values, 1/4 the
ones produces by the counter operator and 1/2 the one produced by the Ratio operator. If we sum together
these value though we obtain a total \sic value of 1 for the query, which indicates that no failure
occurred during the processing. 

