In recent years there has been a growing demand for applications capable of processing high-volume data streams in
real-time~\cite{8-reqs}. These stream based applications include, among others, financial algorithmic
trading~\cite{streambase-algo}, network monitoring~\cite{phi} and environmental monitoring~\cite{swissexp}. 
My research deals with the issues arising when building such a system at extreme scale, able to reliably collect and
distributely process datastreams from a very large number of sources.
The idea of processing streams of data in real-time has been around for a while and many solutions have been proposed in the years.
Different communities have taken different approaches, but we can broadly classify these efforts in three categories.  

The first comprises research projects aiming at the construction of a global sensor infrastructure~\cite{senseweb, gsn,
irisnet} These are concerned mostly with sensor data, trying to develop a common infrastructure in which different
classes of sensors can be connected and accessed through a common interface, allowing users to process data streams
generated by different sensor networks.
 
A second approach is represented by data stream processing systems (DSPSs)~\cite{stream, aurora-and-medusa,
borealis-design, niagaracq, telegraphcq, xstream}. These projects are more general purpose and can be seen as an
extension of classical database systems, but focused on the processing of streams of data. Differently than traditional
databases, where queries are issued over stored data, in DSPSs queries are first submitted to the system and results are
genreated by processing the constant stream of new data pushed into the system.  This allows the generation of real-time
updated results based on the constantly changing available data streams. 

In the third cathegory I place systems dealing with distributed aggregation~\cite{sdims, gossip-aggregates, astrolabe,
dec-net-mon, network-imprecision}.  These are more application specific the formers, as they are mainly concerned with the
computation of aggregate quantities in very large distributed systems.  

In the next section I will introduce some of the applications that can benefit from stream processing, in particular I
will present two application domains in which some degree of failure is inevitable and acceptable.  In
section~\ref{sec:gsi} I will give an overview of some the efforts made in the direction of the construction of a global
sensing infrastructure. In section~\ref{sec:sps-centralized} and \ref{sec:sps-distributed} I will introduce the research
related to stream processing, respectively in its centralised and distributed approaches. Finally, in
section~\ref{sec:dist-agg} I will discuss some efforts dealing with the computation of distributed aggregates.


\begin{comment}

The idea of processing streams of data has been around for a while. The first
attempts made in the area where more Database oriented and focused in the
collection of sensor data and in their centralized processing. An example of
such a system is \emph{SenseWeb}. Another system which greatly contributed to
the system is \emph{STREAM}. It is still a centralized system, but had the merit
of introducing CQL (the Continuos Query Language) which has become one of the
de-facto standards in the field.  \emph{Hi-Fi} is another centralized system
developed to be employed in large-scale supply chain management.  Then it came
\emph{Borealis}: the first distributed stream processing engine. It was built on
the experiences of Aurora and Medusa, bringing for the first time stream
processing out of a single datacenter. Also \emph{IrisNet} proposed a
decentralized processing approach, but their distribution method was too rigid
and not suitable for all queries. Recently \emph{Mortar} entered the scenes
proposing many innovations, and for the first time acknowledging the necessity
of taking failure in to account when working at such a scale.

A more distributed systems approach to the area has been taken by other systems.
\emph{SDIMS}~\cite{sdims} is concerned with distributed monitoring, it aims at
aggregating information about large-scale distributed systems. Similarly to an
ISSP it collects information on rare events or summary views, even though its
scope is limited to aggregation queries. Another work which is worth to mention
is the one about \emph{Network Imprecision}~\cite{network-imprecision}. Here a
new consistency metric is introduced to safeguard accuracy despite node and
network failure. It too is concerned with aggregation queries, but it takes
failure into account. I'll now present some of these systems in more detail,
with particular attention on their dependability issues.

\end{comment}
